# -*- coding: utf-8 -*-
"""Phishing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/160ZE900b7flpIMg8oEl9NvQG7Hmosxry

Importing the Dataset to colab
"""

from google.colab import files
uploaded = files.upload()

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
from sklearn.svm import SVC
#from sklearn.externals import joblib
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score,roc_curve,auc, confusion_matrix
from sklearn import preprocessing
#Seaborn is a Python data visualization library based on matplotlib
import seaborn as sns

#easy simple parallel computing
pip install joblib

# Creating the dataframe  
dataset = pd.read_csv("phishing.csv") 
  
# Print the dataframe 
dataset.head(3)

#print the full summary 
dataset.info()

# Describe statistical information of data
print(dataset.describe())

# Look for missing values
print(dataset.isnull().sum())

#Calculating the number of 0's 1's and -1's in a specific attribute

a=len(dataset[dataset.web_traffic==0])
b=len(dataset[dataset.web_traffic==-1])
c=len(dataset[dataset.web_traffic==1])
print(a,"times 0 repeated in Result")
print(b,"times -1 repeated in Result")
print(c,"times 1 repeated in Result")
sns.countplot(dataset['web_traffic'])

a=len(dataset[dataset.SSLfinal_State==0])
b=len(dataset[dataset.SSLfinal_State==-1])
c=len(dataset[dataset.SSLfinal_State==1])
print(a,"times 0 repeated in Result")
print(b,"times -1 repeated in Result")
print(c,"times 1 repeated in Result")
sns.countplot(dataset['SSLfinal_State'])

# Generate correlation matrix
print(dataset.corr())

"""The heatmap is a way of representing the data in a 2-dimensional form. The data values are represented as colors in the graph. The goal of the heatmap is to provide a colored visual summary of information."""

plt.figure(figsize =(8,8))
sns.heatmap(dataset.corr())    # Generate heatmap (though very less clarity due to large no. of ftrs

print(dataset.corr()['Result'].sort_values())      # Print correlation with target variable



# Remove features having correlation coeff. between +/- 0.03
dataset.drop(['Favicon','Iframe','Redirect','popUpWidnow','RightClick','Submitting_to_email'],axis=1,inplace=True)

"""The training set is a subset of the data set used to train a model.

x_train is the training data set.

y_train is the set of labels to all the data in x_train.

The test set is a subset of the data set that you use to test your model after the model has gone through initial vetting by the validation set.

x_test is the test data set.

y_test is the set of labels to all the data in x_test.

when random_state set to an integer, train_test_split will return same results for each execution.

when random_state set to an None, train_test_split will return different results for each execution.
"""

# Prepare data for models
y = dataset['Result'].values
X = dataset.drop(['Result',], axis = 1)


# Split the data as training and testing data - 70% train size, 30% test size and random state is none means it splits the data randomly
X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size = 0.30, random_state = None)



#1 Classification using Random Forest Classifier
from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier()
rfc = rfc.fit(X_train,y_train)
prediction = rfc.predict(X_test)
acc_RF =accuracy_score(y_test, prediction)
print("Accuracy with RF classifier:",acc_RF) 
fpr,tpr,thresh = roc_curve(y_test,prediction)      
roc_auc = accuracy_score(y_test,prediction)         # Calculate ROC AUC

# Plot ROC curve for Random Forest
plt.plot(fpr,tpr,'g',label = 'Random Forest')
plt.legend("Random Forest", loc='lower right')
plt.legend(loc='lower right')
plt.ylabel('TPR')
plt.xlabel('FPR')
plt.title('ROC Curve')
binary=confusion_matrix(y_test,prediction)
print("Conf matrix RF classifier:\n",confusion_matrix(y_test,prediction))  #  Generate confusion matrix



#2 Classification using SVM
from sklearn.svm import SVC
#c is a regularization parameter
svc_l = SVC(kernel = "linear", C = 0.025)
svc_l = svc_l.fit(X_train,y_train)
prediction = svc_l.predict(X_test)
acc_svm = accuracy_score(y_test, prediction)
print("Accuracy with SVM-Linear:",acc_svm)
fpr,tpr,thresh = roc_curve(y_test,prediction)
roc_auc = accuracy_score(y_test,prediction)

# Plot ROC curve for SVM-linear
plt.plot(fpr,tpr,'b',label = 'SVM')
plt.legend("SVM", loc ='lower right')
plt.legend(loc ='lower right')
print("Conf matrix SVM-linear:",confusion_matrix(y_test,prediction))

plt.show()

sns.pairplot(dataset)
dataset.describe()

from sklearn import tree
from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier

#3 Create Decision Tree classifer object
clf = DecisionTreeClassifier()

# Train Decision Tree Classifer
clf = clf.fit(X_train,y_train)

#Predict the response for test dataset
y_pred = clf.predict(X_test)

from sklearn.metrics import classification_report, confusion_matrix
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))
acc_DT= accuracy_score(y_test, y_pred)
# Plot ROC curve for decsion tree
plt.plot(fpr,tpr,'b',label = 'DT')
plt.legend("DT", loc ='lower right')
plt.legend(loc ='lower right')
plt.xlabel("False positive rate")
plt.ylabel("True positive rate")

plt.show()

# Model Accuracy, how often is the classifier correct?
print("Conf matrix Decsion Tree:\n",confusion_matrix(y_test,prediction))
print("Accuracy:",accuracy_score(y_test, y_pred))

from sklearn.feature_selection import RFE
rfe = RFE(rfc,27)                              
rfe = rfe.fit(X_train, y_train)               # Train RF classifier with only 27 features now
pred = rfe.predict(X_test)
acc_RF_rem =accuracy_score(y_test,pred)
# Test accuracy on reduced data
print("Accuracy by RFClassifier after RFE is applied:",acc_RF_rem )

rfe = RFE(svc_l,27)
rfe = rfe.fit(X_train, y_train)               # Train SVM with only 27 features now
pred = rfe.predict(X_test)
acc_svm_rem =accuracy_score(y_test,pred)
print("Accuracy by SVM after RFE is applied:", acc_svm_rem)

#Comparing performance of all RF with less features
objects = ('Random Forest ','Random Forest with 27 features')
y_pos = np.arange(len(objects))
performance = [acc_RF,acc_RF_rem]

plt.bar(y_pos, performance, align='center', alpha=0.7)
plt.xticks(y_pos, objects)
plt.ylabel('Accuracy')
plt.title('Comparison of Different Models')

plt.show()

#Comparing performance of all models
objects = ('Random Forest','SVM','Decision Tree')
y_pos = np.arange(len(objects))
performance = [acc_RF,acc_svm,acc_DT]

plt.bar(y_pos, performance, align='center', alpha=0.7,width=0.8 ,color=['black', 'red', 'green'], edgecolor='blue')
plt.xticks(y_pos, objects)
plt.ylabel('Accuracy')
plt.title('Comparison of Different Models')
plt.ylim(0.1,1.0) 
#plt.xlim()
#plt.ylim(0.1, 0.2, 0.3, 0.4, 0.5,0.6,0.7,0.8,0.9,1.0)
plt.show()

fig, ax = plt.subplots(figsize=(20,30))
sns.heatmap(dataset.corr(), annot=True,linewidths=2)